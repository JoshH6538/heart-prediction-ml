{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddc62f4e-8ad8-4118-9c47-c0121be796ac",
   "metadata": {},
   "source": [
    "# Decision Tree - Heart Failure Prediction\n",
    "\n",
    "This notebook builds and evaluates a **Decision Tree** model for predicting the likelihood of heart failure based on patient health attributes.\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Use Decision Tree Classifier as a **baseline classifier** to:\n",
    "- Identify which health factors are most strongly associated with heart failure.\n",
    "- Establish a performance benchmark for comparison with more complex models such as Random Forests and Gradient Boosted Trees\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Summary\n",
    "\n",
    "The dataset contains **918 patient records** and **11 health-related features**, along with a binary target variable:\n",
    "\n",
    "- **Target:** `HeartDisease` (1 = patient has or is at risk of heart failure, 0 = otherwise)\n",
    "\n",
    "**Features include:**\n",
    "- *Age, Sex, ChestPainType, RestingBP, Cholesterol, FastingBS, RestingECG, MaxHR, ExerciseAngina, Oldpeak, ST_Slope*\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. **Load the dataset** (`dataset/heart.csv`)  \n",
    "2. **Preprocess features** (encode categorical variables and scale numerical features)  \n",
    "3. **Train and evaluate** a Decision Tree model using both a **standard 80/20 train–test split** and **10-fold cross-validation**  \n",
    "4. **Compare performance** across the two evaluation methods to assess model stability and generalization  \n",
    "5. **Analyze feature coefficients** to identify which clinical and demographic factors most influence heart disease predictions\n",
    "\n",
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "- All preprocessing (encoding, scaling, and splitting) is performed **within this notebook** for simplicity and reproducibility.  \n",
    "- A fixed random seed (`random_state=42`) is used to maintain consistent splits and fair comparisons between methods.  \n",
    "- This notebook establishes a **baseline** for model performance and interpretability, providing a foundation for future experiments with more complex algorithms such as Random Forests and Gradient Boosted Trees.\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecd6e36-d9bd-4460-8541-3c938db22964",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "We load the dataset from *Kaggle's* **.csv** file to initialize a dataframe (`df`).\n",
    "\n",
    "Afterwards, we can verify `df` has been populated and observe the structure of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3950dde6-bbb5-409b-b129-a8c35dac8003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset/heart.csv\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba8d9307-86a5-4f60-8729-e0ac9b62cd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(918, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b3395b-5a62-4a11-9655-44a0908d0be6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of      Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n",
       "0     40   M           ATA        140          289          0     Normal   \n",
       "1     49   F           NAP        160          180          0     Normal   \n",
       "2     37   M           ATA        130          283          0         ST   \n",
       "3     48   F           ASY        138          214          0     Normal   \n",
       "4     54   M           NAP        150          195          0     Normal   \n",
       "..   ...  ..           ...        ...          ...        ...        ...   \n",
       "913   45   M            TA        110          264          0     Normal   \n",
       "914   68   M           ASY        144          193          1     Normal   \n",
       "915   57   M           ASY        130          131          0     Normal   \n",
       "916   57   F           ATA        130          236          0        LVH   \n",
       "917   38   M           NAP        138          175          0     Normal   \n",
       "\n",
       "     MaxHR ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0      172              N      0.0       Up             0  \n",
       "1      156              N      1.0     Flat             1  \n",
       "2       98              N      0.0       Up             0  \n",
       "3      108              Y      1.5     Flat             1  \n",
       "4      122              N      0.0       Up             0  \n",
       "..     ...            ...      ...      ...           ...  \n",
       "913    132              N      1.2     Flat             1  \n",
       "914    141              N      3.4     Flat             1  \n",
       "915    115              Y      1.2     Flat             1  \n",
       "916    174              N      0.0     Flat             1  \n",
       "917    173              N      0.0       Up             0  \n",
       "\n",
       "[918 rows x 12 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cd97bc-1048-4f7e-a27f-6ff582eda919",
   "metadata": {},
   "source": [
    "## Data Preparation and Feature Construction\n",
    "\n",
    "Now that we’ve verified the dataset’s integrity, we can construct the **feature matrix (`X`)** and **label vector (`y`)** for model training.\n",
    "\n",
    "We begin by selecting all relevant feature columns from the dataset.  \n",
    "\n",
    "The target variable, `HeartDisease`, will serve as our label vector (`y`), while the remaining columns form the feature matrix (`X`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a290a8a1-e690-45e2-8724-cf24e74e05f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "100    1\n",
       "200    0\n",
       "300    1\n",
       "400    1\n",
       "500    1\n",
       "600    0\n",
       "700    0\n",
       "800    0\n",
       "900    1\n",
       "Name: HeartDisease, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# label vector\n",
    "y = df['HeartDisease']\n",
    "y[::100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0815136-653a-44b4-ba62-a08cc452b504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>130</td>\n",
       "      <td>275</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>115</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>47</td>\n",
       "      <td>M</td>\n",
       "      <td>TA</td>\n",
       "      <td>110</td>\n",
       "      <td>249</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>150</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>60</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>149</td>\n",
       "      <td>N</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>50</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>160</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Normal</td>\n",
       "      <td>110</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>65</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>136</td>\n",
       "      <td>248</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>140</td>\n",
       "      <td>Y</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>130</td>\n",
       "      <td>207</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>96</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>TA</td>\n",
       "      <td>148</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "      <td>LVH</td>\n",
       "      <td>178</td>\n",
       "      <td>N</td>\n",
       "      <td>0.8</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>43</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>130</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>162</td>\n",
       "      <td>N</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>58</td>\n",
       "      <td>M</td>\n",
       "      <td>ASY</td>\n",
       "      <td>114</td>\n",
       "      <td>318</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>140</td>\n",
       "      <td>N</td>\n",
       "      <td>4.4</td>\n",
       "      <td>Down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  \\\n",
       "0     40   M           ATA        140          289          0     Normal   \n",
       "100   65   M           ASY        130          275          0         ST   \n",
       "200   47   M            TA        110          249          0     Normal   \n",
       "300   60   M           ASY        160            0          1     Normal   \n",
       "400   50   F           ASY        160            0          1     Normal   \n",
       "500   65   M           ASY        136          248          0     Normal   \n",
       "600   57   M           ASY        130          207          0         ST   \n",
       "700   42   M            TA        148          244          0        LVH   \n",
       "800   43   M           NAP        130          315          0     Normal   \n",
       "900   58   M           ASY        114          318          0         ST   \n",
       "\n",
       "     MaxHR ExerciseAngina  Oldpeak ST_Slope  \n",
       "0      172              N      0.0       Up  \n",
       "100    115              Y      1.0     Flat  \n",
       "200    150              N      0.0       Up  \n",
       "300    149              N      0.4     Flat  \n",
       "400    110              N      0.0     Flat  \n",
       "500    140              Y      4.0     Down  \n",
       "600     96              Y      1.0     Flat  \n",
       "700    178              N      0.8       Up  \n",
       "800    162              N      1.9       Up  \n",
       "900    140              N      4.4     Down  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cols = df.columns[:-1]\n",
    "\n",
    "# feature matrix\n",
    "X = df[features_cols]\n",
    "X[::100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5529cb64-ff62-4fd5-80ce-8ee8e0ec6cc5",
   "metadata": {},
   "source": [
    "With the data prepared, we now split it into **training** and **testing** subsets to evaluate how well the model generalizes to unseen data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485877e-e45d-4dda-83d5-88f9faa22ddd",
   "metadata": {},
   "source": [
    "## Splitting the Data for Model Evaluation\n",
    "\n",
    "To properly assess our Decision Tree model, we need to separate the dataset into distinct training and evaluation sets.  \n",
    "This ensures that the model is tested on unseen data and prevents overfitting.\n",
    "\n",
    "We will explore **two common evaluation strategies**:\n",
    "\n",
    "1. **Standard Train/Test Split** – a single 80/20 split providing a quick baseline of model performance.  \n",
    "2. **k-Fold Cross-Validation** – a more robust method that repeatedly trains and tests the model across multiple data partitions.\n",
    "\n",
    "By comparing results from both approaches, we can evaluate the **stability and consistency** of our model’s predictions and choose the most reliable validation strategy for further tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79740075-4c30-4713-8792-41d7b070d7b7",
   "metadata": {},
   "source": [
    "## Standard Train/Test Split\n",
    "\n",
    "We begin by establishing a **baseline performance** for our Decision Tree model using a simple 80/20 train–test split.  \n",
    "This approach provides an initial benchmark for accuracy and other key metrics before applying more rigorous validation methods such as k-fold cross-validation.\n",
    "\n",
    "The data is split into **training** and **testing** subsets using `train_test_split`.\n",
    "\n",
    "We will use the following parameters: `test_size`=**0.2**, `random_state`=**42**.\n",
    "\n",
    "Our *test size* indicates that our training dataset will take up 80% of the total dataset while the testing set takes up 20%.\n",
    "\n",
    "Our *random state* is a seed that allows us to have replicable results when splitting the data.\n",
    "\n",
    "We then train the Decision Tree model on the training data and evaluate it on the unseen test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dcab3fb-637c-4925-a703-542504c7cf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into testing and training sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size = 0.2, random_state = 42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08195712-05ae-43e9-948c-fdf5ef00e082",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "The Decision Tree Model does not require feature scaling despite the scale differences in the dataset. This is because Decision Trees work with relative ordering and split points. Threshold values for each feature depend on information gain rather than scale, meaning the tree structure is unaffected by differences in feature magnitude.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bb24ccd-114f-44a9-b143-47aa4ffed4e3",
   "metadata": {},
   "source": [
    "## Encoding Categorical Features\n",
    "Several features in this dataset are **categorical** (e.g., `Sex`, `ChestPainType`, `RestingECG`, `ExerciseAngina`, `ST_Slope`), and must be encoded. During encoding, the categorical features are converted into numeric values, since sklearn's Decision Tree model only processes numerical data.\n",
    "\n",
    "We use scikit-learn’s `OneHotEncoder` to transform these categorical columns into binary indicator variables.  \n",
    "This creates a new set of columns representing each category, allowing the model to learn from categorical distinctions without assuming any ordinal relationship.\n",
    "\n",
    "> **Note:** We set `sparse_output=False` so that the encoder returns a dense NumPy array, which can easily be converted into a Pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83496c3d-e25a-4dff-9e9f-ecc418cd6c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Sex_M  ChestPainType_ATA  ChestPainType_NAP  ChestPainType_TA  \\\n",
      "0      1.0                0.0                1.0               0.0   \n",
      "1      1.0                0.0                1.0               0.0   \n",
      "2      1.0                0.0                0.0               0.0   \n",
      "3      0.0                0.0                1.0               0.0   \n",
      "4      1.0                0.0                0.0               0.0   \n",
      "..     ...                ...                ...               ...   \n",
      "729    0.0                0.0                0.0               0.0   \n",
      "730    1.0                0.0                0.0               0.0   \n",
      "731    1.0                0.0                0.0               0.0   \n",
      "732    1.0                0.0                0.0               0.0   \n",
      "733    0.0                0.0                0.0               0.0   \n",
      "\n",
      "     RestingECG_Normal  RestingECG_ST  ExerciseAngina_Y  ST_Slope_Flat  \\\n",
      "0                  1.0            0.0               0.0            0.0   \n",
      "1                  1.0            0.0               0.0            0.0   \n",
      "2                  1.0            0.0               1.0            1.0   \n",
      "3                  1.0            0.0               0.0            0.0   \n",
      "4                  1.0            0.0               0.0            1.0   \n",
      "..                 ...            ...               ...            ...   \n",
      "729                0.0            1.0               0.0            0.0   \n",
      "730                1.0            0.0               0.0            0.0   \n",
      "731                1.0            0.0               1.0            0.0   \n",
      "732                0.0            1.0               1.0            0.0   \n",
      "733                1.0            0.0               0.0            1.0   \n",
      "\n",
      "     ST_Slope_Up  Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  \n",
      "0            0.0   42        120          240          1    194      0.8  \n",
      "1            1.0   36        130          209          0    178      0.0  \n",
      "2            0.0   56        150          213          1    125      1.0  \n",
      "3            1.0   37        130          211          0    142      0.0  \n",
      "4            0.0   51        120            0          1    104      0.0  \n",
      "..           ...  ...        ...          ...        ...    ...      ...  \n",
      "729          1.0   48        120          254          0    110      0.0  \n",
      "730          1.0   45        120          225          0    140      0.0  \n",
      "731          1.0   60        130          253          0    144      1.4  \n",
      "732          1.0   60        152            0          0    118      0.0  \n",
      "733          0.0   40        150          392          0    130      2.0  \n",
      "\n",
      "[734 rows x 15 columns]\n",
      "     Sex_M  ChestPainType_ATA  ChestPainType_NAP  ChestPainType_TA  \\\n",
      "0      0.0                1.0                0.0               0.0   \n",
      "1      1.0                0.0                1.0               0.0   \n",
      "2      1.0                0.0                0.0               0.0   \n",
      "3      1.0                0.0                0.0               0.0   \n",
      "4      1.0                1.0                0.0               0.0   \n",
      "..     ...                ...                ...               ...   \n",
      "179    0.0                0.0                1.0               0.0   \n",
      "180    0.0                0.0                0.0               0.0   \n",
      "181    1.0                0.0                0.0               0.0   \n",
      "182    1.0                1.0                0.0               0.0   \n",
      "183    1.0                0.0                0.0               0.0   \n",
      "\n",
      "     RestingECG_Normal  RestingECG_ST  ExerciseAngina_Y  ST_Slope_Flat  \\\n",
      "0                  1.0            0.0               0.0            0.0   \n",
      "1                  1.0            0.0               0.0            1.0   \n",
      "2                  0.0            1.0               0.0            1.0   \n",
      "3                  0.0            0.0               1.0            1.0   \n",
      "4                  1.0            0.0               0.0            0.0   \n",
      "..                 ...            ...               ...            ...   \n",
      "179                1.0            0.0               1.0            1.0   \n",
      "180                1.0            0.0               1.0            1.0   \n",
      "181                0.0            1.0               1.0            1.0   \n",
      "182                1.0            0.0               0.0            0.0   \n",
      "183                0.0            1.0               1.0            1.0   \n",
      "\n",
      "     ST_Slope_Up  Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  \n",
      "0            1.0   63        140          195          0    179      0.0  \n",
      "1            0.0   53        145          518          0    130      0.0  \n",
      "2            0.0   65        160            0          1    122      1.2  \n",
      "3            0.0   56        130            0          0    122      1.0  \n",
      "4            1.0   54        108          309          0    156      0.0  \n",
      "..           ...  ...        ...          ...        ...    ...      ...  \n",
      "179          0.0   50        140          288          0    140      0.0  \n",
      "180          0.0   63        108          269          0    169      1.8  \n",
      "181          0.0   64        141          244          1    116      1.5  \n",
      "182          1.0   49        130          266          0    171      0.6  \n",
      "183          0.0   64        144            0          0    122      1.0  \n",
      "\n",
      "[184 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first', sparse_output = False) # use drop first to avoid redundacy\n",
    "\n",
    "cat_feature_cols = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
    "num_features_cols = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak']\n",
    "\n",
    "# encode the categorical features\n",
    "X_train_cat = encoder.fit_transform(X_train[cat_feature_cols])\n",
    "X_test_cat = encoder.transform(X_test[cat_feature_cols])\n",
    "\n",
    "# Get the encoded column names\n",
    "encoded_cols = encoder.get_feature_names_out(cat_feature_cols)\n",
    "\n",
    "# convert categorical features to Dataframes\n",
    "X_train_encoded = pd.DataFrame(X_train_cat, columns=encoded_cols).reset_index(drop=True)\n",
    "X_test_encoded = pd.DataFrame(X_test_cat, columns=encoded_cols).reset_index(drop=True)\n",
    "\n",
    "# Combine the numerical and categorical features\n",
    "\n",
    "# Obtain the numerical Dataframe\n",
    "X_train_num = X_train[num_features_cols].reset_index(drop=True)\n",
    "X_test_num = X_test[num_features_cols].reset_index(drop=True)\n",
    "\n",
    "# combine\n",
    "X_train_final = pd.concat([X_train_encoded,X_train_num], axis=1).reset_index(drop=True)\n",
    "X_test_final = pd.concat([X_test_encoded,X_test_num], axis=1).reset_index(drop=True)\n",
    "\n",
    "# check data\n",
    "print(X_train_final)\n",
    "print(X_test_final)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae54e9bd-6dc1-46ac-b955-90a810141909",
   "metadata": {},
   "source": [
    "## Training the Decision Tree Model\n",
    "\n",
    "Next, we initialize and fit the **Decision Tree** model using the training data, then generate predictions and predicted probabilities for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "639bc223-b00c-4ee9-9eba-ec4be6fd5669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8369565217391305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "decision_tree.fit(X_train_final, y_train)\n",
    "\n",
    "y_pred = decision_tree.predict(X_test_final)\n",
    "\n",
    "dt_acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(dt_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024bfb7b-cd09-47a3-a690-91f7ed1d6530",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
