{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8ddcfbf-e3a6-4187-84b6-d70e2bcd01a8",
   "metadata": {},
   "source": [
    "# Logistic Regression - Heart Failure Prediction\n",
    "\n",
    "This notebook builds and evaluates a **Logistic Regression** model for predicting the likelihood of heart failure based on patient health attributes.  \n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "Use Logistic Regression as a **baseline classifier** to:\n",
    "- Identify which health factors are most strongly associated with heart failure\n",
    "- Establish a performance benchmark for comparison with more complex models such as Decision Trees, Random Forests, and Gradient Boosted Trees\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset Summary\n",
    "\n",
    "The dataset contains **918 patient records** and **11 health-related features**, along with a binary target variable:\n",
    "\n",
    "- **Target:** `HeartDisease` (1 = patient has or is at risk of heart failure, 0 = otherwise)\n",
    "\n",
    "**Features include:**\n",
    "- *Age, Sex, ChestPainType, RestingBP, Cholesterol, FastingBS, RestingECG, MaxHR, ExerciseAngina, Oldpeak, ST_Slope*\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. **Load the dataset** (`dataset/heart.csv`)  \n",
    "2. **Explore and clean data**  \n",
    "3. **Preprocess features** (encode categorical variables, scale numerical features)  \n",
    "4. **Train/test split** to evaluate model generalization  \n",
    "5. **Build and train** a Logistic Regression model  \n",
    "6. **Evaluate performance** using metrics such as Accuracy, F1-score, and ROC-AUC  \n",
    "7. **Interpret coefficients** to understand key risk indicators\n",
    "\n",
    "---\n",
    "\n",
    "##  Notes\n",
    "\n",
    "- All preprocessing for this model (encoding, scaling, and splitting) is handled **within this notebook** for simplicity.  \n",
    "- The same random seed (`random_state=42`) will be used across models to ensure consistent splits and fair performance comparison.  \n",
    "- Results here will serve as a **baseline** for evaluating more advanced models later in the project.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2ec642-81de-4e5e-abc9-280c56cb670d",
   "metadata": {},
   "source": [
    "## Loading the Dataset\n",
    "\n",
    "We load the dataset from *Kaggle's* **.csv** file to initialize a dataframe (`df`).\n",
    "\n",
    "Afterwards, we can verify `df` has been populated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "881f020b-3f4c-4ef8-894c-fe77ee1544a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age               0\n",
       "Sex               0\n",
       "ChestPainType     0\n",
       "RestingBP         0\n",
       "Cholesterol       0\n",
       "FastingBS         0\n",
       "RestingECG        0\n",
       "MaxHR             0\n",
       "ExerciseAngina    0\n",
       "Oldpeak           0\n",
       "ST_Slope          0\n",
       "HeartDisease      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dataset/heart.csv\")\n",
    "\n",
    "df.head()\n",
    "df.duplicated().sum()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
